# バグ収束推定ツール (Bug Convergence Tool)

バイブコーディングで開発したツール。
.NET 8で実装されたソフトウェアテスト品質分析のためのコマンドラインツールです。  
信頼度成長モデル（SRGM）を用いて、バグの収束状況を分析し、リリース判断に役立つ情報を提供します。

## 特徴

### 基本機能

- **6種類の基本信頼度成長モデル**（指数型、遅延S字型、ゴンペルツ、Shiftedゴンペルツ、Ohba型、ロジスティック）
- **不完全デバッグモデル**（バグ修正時の新規バグ混入を考慮）
- **収束予測日の計算**（90%/95%/99%発見予測）
- **グラフ画像出力**（PNG形式）
- **Excel形式での結果出力**
- **詳細なテキストレポート**出力

### 推定・検証機能

- **損失関数の選択**: SSE（残差二乗和）またはMLE（最尤推定、Poisson-NHPP）
- **ホールドアウト検証**: 末尾N日をテスト用に分割し、予測精度（MSE/MAPE）を評価
- **警告メッセージシステム**: データ品質やモデル選択に関する注意点を自動生成
- **AICc自動適用**: 小標本補正AICを自動判定・適用（Burnham & Anderson基準）
- **感度分析**: パラメータの弾力性（Elasticity）を計算し、予測のロバスト性を評価
- **堅牢な変化点検出**: プロファイル尤度法による客観的な変化点特定

### 統計診断・検証機能

- **残差診断**: 生残差・Pearson残差・Deviance残差・Anscombe残差の計算と分析
  - **自己相関検定**: Durbin-Watson検定、Ljung-Box Q検定
  - **正規性検定**: Jarque-Bera検定、Anderson-Darling検定
  - **ランテスト**: 残差の独立性検証
  - **Poisson整合性診断**: 過分散検定、ランダム化分位残差（Dunn & Smyth 1996）
- **適合度検定**: χ²検定、Kolmogorov-Smirnov検定、Cramér-von Mises検定
- **予測区間**: パラメトリックブートストラップによる信頼区間・予測区間の計算
- **モデル平均化**: AIC重み付けによるマルチモデル推論（Burnham & Anderson 2002）

### 高度な統計機能（v2.0新機能）

- **パラメトリック・ブートストラップ（Poisson再生成）**: NHPP仮定に整合したブートストラップ信頼区間
- **変化点の尤度比検定（LRT）**: 変化点の存在を統計的に検定（Davies 1987のシミュレーション法）
- **マルチスタート最適化**: Latin Hypercube Samplingによる多様な初期点からの大域的探索
- **Fisher情報行列ベースの信頼区間**: 解析的な漸近信頼区間の計算（NHPP対数尤度のヘッセ行列）

## 必要環境

- .NET 8.0 SDK / Runtime

## インストール

```bash
# ビルド
dotnet build -c Release

# 発行（単一実行ファイル）
dotnet publish -c Release -r win-x64 --self-contained -p:PublishSingleFile=true -p:PublishReadyToRun=true
```

## 使用方法

```bash
BugConvergenceTool <入力Excel> [オプション]
```

### オプション一覧

| オプション | 説明 |
|-----------|------|
| `-h`, `--help` | ヘルプを表示 |
| `-o`, `--output DIR` | 出力ディレクトリを指定 |
| `-c`, `--config FILE` | 設定ファイルを指定 |
| `-v`, `--verbose` | 詳細出力 |
| `--basic-only` | 基本モデルのみ使用 |
| `--optimizer TYPE` | 最適化アルゴリズム（de/pso/gwo/cmaes/nm/grid/auto） |
| `--change-point` | 変化点モデルを含める |
| `--tef` | テスト工数関数モデルを含める |
| `--fre` | 欠陥除去効率モデルを含める |
| `--coverage` | Coverageモデルを含める |
| `--all-extended` | 全拡張モデルを含める |
| `--ci`, `--confidence-interval` | 95%信頼区間を計算（ブートストラップ法） |
| `--bootstrap N` | ブートストラップ反復回数（デフォルト: 200） |
| `--loss TYPE` | 損失関数を指定（sse/mle） |
| `--holdout-days N` | 末尾N日をホールドアウト検証に使用 |
| `-d`, `--diagnostics` | 統計診断を実行（残差分析、自己相関、正規性、適合度検定） |
| `--pi`, `--prediction-interval` | 予測区間を計算（パラメトリックブートストラップ） |
| `--ma`, `--model-averaging` | モデル平均化を実行（AIC重み付け予測） |

### 使用例

```bash
# 基本的な使用法
BugConvergenceTool TestData.xlsx

# 出力先を指定
BugConvergenceTool TestData.xlsx -o ./output

# オプティマイザ指定
BugConvergenceTool TestData.xlsx --optimizer pso
BugConvergenceTool TestData.xlsx --optimizer auto -v

# 拡張モデル使用
BugConvergenceTool TestData.xlsx --change-point      # 変化点モデル
BugConvergenceTool TestData.xlsx --tef               # TEFモデル
BugConvergenceTool TestData.xlsx --fre               # FREモデル
BugConvergenceTool TestData.xlsx --coverage          # Coverageモデル
BugConvergenceTool TestData.xlsx --all-extended      # 全拡張モデル
BugConvergenceTool TestData.xlsx --all-extended -v   # 詳細出力付き

# 信頼区間付き分析
BugConvergenceTool TestData.xlsx --ci                # 95%信頼区間を計算
BugConvergenceTool TestData.xlsx --ci --bootstrap 500  # 反復回数を増やして精度向上

# 損失関数とホールドアウト検証
BugConvergenceTool TestData.xlsx --loss mle          # MLE（最尤推定）を使用
BugConvergenceTool TestData.xlsx --holdout-days 5    # 末尾5日でホールドアウト検証
BugConvergenceTool TestData.xlsx --loss mle --holdout-days 5 -v  # 組み合わせ

# 組み合わせ
BugConvergenceTool TestData.xlsx --optimizer auto --all-extended --ci --loss mle -o ./results -v

# 統計診断を実行
BugConvergenceTool TestData.xlsx -d                  # 残差診断・適合度検定
BugConvergenceTool TestData.xlsx --diagnostics -v    # 詳細診断レポート

# 予測区間を計算
BugConvergenceTool TestData.xlsx --pi                # 予測区間（ブートストラップ）
BugConvergenceTool TestData.xlsx --pi --bootstrap 500  # 反復回数を増やす

# モデル平均化（マルチモデル推論）
BugConvergenceTool TestData.xlsx --ma                # AIC重み付け予測
BugConvergenceTool TestData.xlsx --ma -v             # 重みと不確実性を表示

# 総合分析
BugConvergenceTool TestData.xlsx --all-extended --loss mle --holdout-days 5 -d --pi --ma --ci -o ./results -v
```

## 入力Excelの形式

「データ入力」シートに以下の形式でデータを配置してください：

```text
        |  B   |  C   |  D   |  E   | ...
--------|------|------|------|------|----
行2     | プロジェクト名         |
行3     | 総テストケース数       |
行4     | テスト開始日           |
        |      |      |      |      |
行6     | 1/6  | 1/7  | 1/8  | 1/9  | ...  ← 日付
行7     |  20  |  25  |  25  |  30  | ...  ← 予定消化（日次）
行8     |  15  |  22  |  28  |  25  | ...  ← 実績消化（日次）
行9     |   8  |  12  |  15  |  10  | ...  ← バグ発生（日次）
行10    |   2  |   5  |   8  |  10  | ...  ← バグ修正（日次）
```

## 出力ファイル

```text
output/
├── Result_YYYYMMDD_HHmmss.xlsx    # 計算結果Excel
├── Result_YYYYMMDD_HHmmss.txt     # テキストレポート
└── Charts_YYYYMMDD_HHmmss/
    ├── test_progress.png          # テスト消化曲線
    ├── bug_cumulative.png         # バグ累積曲線
    ├── remaining_bugs.png         # 残存バグ推移
    ├── bug_convergence.png        # バグ収束確認グラフ
    └── reliability_growth.png     # 信頼度成長曲線
```

## 利用可能なモデル

### 基本モデル（6種類）

| モデル名 | 数式 | 特徴 |
|---------|------|------|
| 指数型（Goel-Okumoto） | m(t) = a(1 - e^(-bt)) | 最もシンプル、バグ発見率一定 |
| 遅延S字型 | m(t) = a(1 - (1+bt)e^(-bt)) | テスト初期の習熟を考慮 |
| ゴンペルツ | m(t) = a·e^(-b·e^(-ct)) | 終盤の収束が急（注: m(0)≠0） |
| Shiftedゴンペルツ | m(t) = a(e^(-b·e^(-ct)) - e^(-b)) | シフトゴンペルツ型。m(0)=0保証、漸近値はa(1-e^(-b)) |
| Ohba型（Weibull） | m(t) = a(1 - e^(-b·t^c)) | 一般化指数型。c>1でS字、c=1で指数型、c<1で凸型 |
| ロジスティック | m(t) = a / (1 + e^(-b(t-c))) | 対称S字カーブ |

> **学術的注記**:
>
> - Ohba型モデルは Ohba, M. (1984). "Software Reliability Analysis Models." IBM Journal of Research and Development に基づきます。
> - Shiftedゴンペルツの漸近値は a ではなく a(1-e^(-b)) です（b=3で約95%、b=5で約99%がaに到達）。
> - Shiftedゴンペルツは統計学のShifted Gompertz分布のSRGMへの応用であり、標準的なゴンペルツSRGM文献とは異なる形式です。

#### 基本モデルのパラメータ

| モデル | パラメータ | 探索範囲 | 意味 |
|--------|-----------|---------|------|
| **指数型** | a | [maxY, maxY×5] | 総バグ数 |
| | b | [0.001, 1.0] | 発見率 |
| **遅延S字型** | a | [maxY, maxY×5] | 総バグ数 |
| | b | [0.001, 1.0] | 発見率 |
| **ゴンペルツ** | a | [maxY, maxY×5] | 総バグ数 |
| | b | [0.1, 10.0] | 初期遅延係数 |
| | c | [0.001, 1.0] | 成長率 |
| **Shiftedゴンペルツ** | a | [maxY, maxY×6] | スケールパラメータ（漸近値は a(1-e^(-b))） |
| | b | [0.5, 10.0] | 初期遅延係数（大きいほど漸近値→a） |
| | c | [0.001, 1.0] | 成長率 |
| **Ohba型（Weibull）** | a | [maxY, maxY×5] | 総バグ数（漸近値） |
| | b | [0.0001, 1.0] | スケールパラメータ |
| | c | [0.3, 3.0] | 形状パラメータ（c>1でS字型） |
| **ロジスティック** | a | [maxY, maxY×5] | 総バグ数 |
| | b | [0.01, 2.0] | 成長率 |
| | c | [1.0, n×2] | 変曲点（日） |

※ maxY: 観測データの最大累積バグ数、n: データ点数

### 不完全デバッグ考慮モデル（2種類）

| モデル名 | 数式 | 特徴 |
|---------|------|------|
| Pham型不完全デバッグ指数 | m(t) = a(1-e^(-bt)) / (1+p·e^(-bt)) | Pham (1993) 型。修正時の新バグ発生を考慮 |
| Weibull型不完全デバッグ | m(t) = a(1-e^(-bt^c)) / (1+p(1-e^(-bt^c))) | Pham型をWeibull発見率に拡張。c>1でS字、c=1で指数型、c<1で凸型 |

> **学術的注記**: 
> 上記の数式は Pham, H. (1993) "Software Reliability Assessment" の不完全デバッグモデルに基づく形式です。
> これは Pham-Nordmann-Zhang (1999) モデル（PNZモデル）とは異なります。
> 正確な PNZ モデルは m(t) = a(1-e^(-(b+α)t))/(1+(α/b)e^(-bt)) です。
> Weibull型は Pham (2006) "System Software Reliability" の一般化形式に基づきます。

#### 不完全デバッグモデルのパラメータ

| モデル | パラメータ | 探索範囲 | 意味 |
|--------|-----------|---------|------|
| **Pham型不完全デバッグ指数** | a | [maxY, maxY×5] | 潜在欠陥数のスケールパラメータ |
| | b | [0.001, 1.0] | 欠陥検出率 |
| | p | [0.0, 0.99] | 不完全デバッグ係数（0で完全デバッグ） |
| **Weibull型不完全デバッグ** | a | [maxY, maxY×5] | 潜在欠陥数のスケールパラメータ |
| | b | [0.001, 1.0] | 欠陥検出率のスケール |
| | c | [0.5, 2.0] | 形状パラメータ（c>1で初期遅延S字、c<1で初期加速凸型） |
| | p | [0.0, 0.99] | 不完全デバッグ係数 |

#### パラメータの解釈（不完全デバッグ系モデル共通）

- **a（潜在欠陥数スケール）**
  潜在バグ総数の規模を表すスケールパラメータ。
  完全デバッグ（p = 0）の場合、時間が十分経過したときの累積検出バグ数の上限に対応する（m(∞) → a）。

- **b（欠陥検出率）**
  バグが検出される速さを表すパラメータ。
  b が大きいほど曲線の立ち上がりが急になり、早期に収束しやすい。

- **p（不完全デバッグ係数）**
  デバッグ時に新たなバグがどの程度混入するかを表す（0 ≤ p < 1）。
  - **p > 0**: 不完全デバッグ。修正時に新バグが混入し、信頼性成長が遅くなる。
  - **p = 0**: 完全デバッグ。修正による新バグ混入はない（従来の指数型モデルと同等）。

### 変化点モデル（実効時間方式）

テスト方針や環境が途中で変わるケースに対応する拡張モデルです。

| モデル名 | 数式 | 特徴 |
|---------|------|------|
| 不完全デバッグ+変化点 | m(t) = a(1-e^(-u(t)))/(1+p·e^(-u(t))) | 不完全デバッグモデルに検出率変化点を導入 |

#### 実効時間 u(t) の定義

```text
u(t) = b₁·t           （t ≤ τ）
u(t) = b₁·τ + b₂·(t-τ) （t > τ）
```

- **τ（変化点）**: テスト方針・環境が変わる時刻
- **b₁**: 変化点前の検出率
- **b₂**: 変化点後の検出率

この方式により m(t) は変化点 τ の前後で自動的に連続となります。

#### パラメータ

| パラメータ | 探索範囲 | 意味 |
|-----------|---------|------|
| a | [maxY, maxY×100] | 潜在欠陥数スケール |
| b₁ | [1e-8, 10.0] | 変化点前の検出率 |
| b₂ | [1e-8, 10.0] | 変化点後の検出率 |
| p | [0.0, 5.0] | 不完全デバッグ係数 |
| τ | [2, n-2] | 変化点時刻（n=データ点数） |

#### 解釈

- **b₂ > b₁**: テスト強化（変化点以降の収束が加速）
- **b₂ < b₁**: テスト弱体化（変化点以降の収束が減速）
- **b₂ ≈ b₁**: 変化点の影響が小さい（通常の不完全デバッグモデルに近い）

### 擬似Coverageモデル（パラメトリック NHPP）

時間 t の関数として擬似的なカバレッジを近似し、m(t) = a · C(t) として定義するモデル群です。
実測カバレッジデータがなくても、時間を説明変数としてカバレッジ的な振る舞いを表現できます。

> **学術的注記**: これらは「時間ベースの擬似カバレッジモデル」であり、
> 実測カバレッジデータを使用する真のカバレッジベースSRGMとは区別されます。
> 実測カバレッジデータがある場合は、それを直接説明変数として使用することを推奨します。

> **実行時の注意**: Weibull型擬似Coverageは基本モデルのOhba型（Weibull）と数学的に同等のため、
> デフォルトでは実行対象から除外されています。Logistic型とGompertz型のみが実行されます。

| モデル名 | 擬似カバレッジ関数 C(t) | 特徴 | 実行 |
|---------|-------------------|------|------|
| Weibull型擬似Coverage | 1 - e^(-(βt)^γ) | Ohba型と数学的に同等 | ❌ 除外 |
| Logistic型擬似Coverage | 1 / (1 + e^(-β(t-τ))) | τで擬似Coverage50%となる対称S字型 | ✅ |
| Gompertz型擬似Coverage | exp(-e^(-β(t-τ))) | 非対称S字型、初期の遅い立ち上がり | ✅ |

#### ~~Weibull型擬似Coverage のパラメータ~~（Ohba型と重複のため除外）

| パラメータ | 探索範囲 | 意味 |
|-----------|---------|------|
| a | [maxY, maxY×100] | 総バグ数（m(∞) = a） |
| β | [1e-8, 10.0] | 時間スケール（大きいほど立ち上がりが早い） |
| γ | [0.1, 5.0] | 形状パラメータ |

※ このモデルは `m(t) = a(1 - e^(-(βt)^γ))` であり、Ohba型 `m(t) = a(1 - e^(-b·t^c))` と変数名が異なるだけで同一の数式です。

#### Logistic型擬似Coverage のパラメータ

| パラメータ | 探索範囲 | 意味 |
|-----------|---------|------|
| a | [maxY, maxY×100] | 総バグ数 |
| β | [0.01, 10.0] | 立ち上がりの鋭さ |
| τ | [1, n] | 擬似Coverage50%到達時刻（n=データ点数） |

#### Gompertz型擬似Coverage のパラメータ

| パラメータ | 探索範囲 | 意味 |
|-----------|---------|------|
| a | [maxY, maxY×100] | 総バグ数 |
| β | [0.001, 5.0] | 増加率 |
| τ | [1, n] | 変曲点時刻（n=データ点数） |

## 損失関数

パラメータ推定に使用する損失関数を選択できます。

### SSE（残差二乗和）- デフォルト

従来の最小二乗法です。累積バグ数に対する残差の二乗和を最小化します。

```text
SSE = Σ(yᵢ - m(tᵢ; θ))²
```

- **メリット**: 計算が安定、外れ値に敏感で異常検出に有用
- **デメリット**: 確率的な解釈が難しい

### MLE（最尤推定）- Poisson-NHPP

日次バグ数がポアソン分布に従うと仮定した最尤推定です。非斉次ポアソン過程（NHPP）に基づく負の対数尤度を最小化します。

```text
NLL = Σ(λᵢ - yᵢ·log(λᵢ))
where λᵢ = m(tᵢ) - m(tᵢ₋₁)  （期待される日次バグ数）
```

- **メリット**: 確率論的に正しい推定、信頼区間との親和性が高い
- **デメリット**: 日次バグ数が0の日が多いとやや不安定

### 対応モデル

| 損失関数 | 対応モデル |
|---------|------------|
| SSE | 全モデル |
| MLE | 全モデル |

全モデルでMLE（最尤推定）をサポートしています。ソフトウェア信頼度成長モデル（SRGM）は非斉次ポアソン過程（NHPP）として定義されており、MLEは数学的に最も自然なアプローチです。

> **推奨**: 複雑なモデル（不完全デバッグ、FRE等）でMLEを使用する場合、計算安定性のため `--optimizer de` または `--optimizer cmaes` の指定を推奨します。勾配法ベースのオプティマイザでは収束しない可能性があります。

### FREモデルの同時最尤推定

欠陥除去効率（FRE）モデルでは、バグ発見プロセスとバグ修正プロセスの両方を同時に評価する「同時最尤推定（Simultaneous MLE）」を実装しています。

```text
ln(L_total) = ln(L_detected) + ln(L_corrected)

where L_detected = バグ発見数の尤度（NHPPベース）
      L_corrected = バグ修正数の尤度（NHPPベース）
```

これにより、η（欠陥除去効率）などのパラメータがより正確に推定されます。

### AIC（赤池情報量規準）の計算

AICはモデル比較に使用される指標で、値が小さいほど良いモデルとされます。本ツールでは損失関数の種類に応じて、統計的に一貫した方法でAICを計算します。

#### SSE使用時（正規分布仮定）

```text
AIC = n × ln(SSE/n) + 2k
```

最小二乗法における残差の正規性を仮定した近似式です。

#### MLE使用時（Poisson-NHPP）

```text
AIC = 2k - 2ln(L)

where ln(L) = Σ[yᵢ × ln(λᵢ) - λᵢ - ln(yᵢ!)]
      λᵢ = m(tᵢ) - m(tᵢ₋₁)  （期待される日次バグ数）
```

ポアソン分布に基づく対数尤度から正式なAIC定義に従って計算します。

#### FREモデルの場合（同時最尤推定）

FREモデルでは、発見数と修正数の結合尤度を使用してAICを計算します。

```text
AIC = 2k - 2ln(L_total)
    = 2k - 2(ln(L_d) + ln(L_c))

where L_d = バグ発見数の尤度
      L_c = バグ修正数の尤度
```

> **注意**: SSEとMLEでAICの絶対値スケールが異なるため、異なる損失関数で推定したモデル間のAIC比較は推奨されません。モデル比較は同一の損失関数で統一してください。

### AICc（小標本補正AIC）の自動適用

本ツールでは、Burnham & Anderson (2002) の基準に基づき、サンプルサイズが小さい場合に自動的にAICc（小標本補正AIC）を適用します。

#### AICcの定義

```text
AICc = AIC + 2k(k+1) / (n-k-1)

where n = サンプルサイズ（データ日数）
      k = パラメータ数
```

#### 自動判定ロジック

| 条件 | 使用される基準 | 理由 |
|------|---------------|------|
| n ≤ k+1 | **Invalid（評価不能）** | 分母が0以下となり計算不可。モデルとして不適 |
| n/k < 40 | **AICc** | 小標本補正が必要（Burnham & Anderson 推奨） |
| n/k ≥ 40 | **AIC** | 十分なサンプルサイズがあり補正項は無視できる |

> **注意**: n → ∞ で AICc は AIC に収束するため、常に AICc を使用しても学術的に問題ありません。

#### 補正の効果

AICcの補正項 `2k(k+1)/(n-k-1)` は、パラメータ数 k が大きく、サンプルサイズ n が小さいほど大きなペナルティを与えます。

**例**: データ日数 n=20、パラメータ数 k=6 の場合

```text
補正項 = 2×6×7 / (20-6-1) = 84/13 ≈ 6.46
```

この補正により、データ数が少ない状況では複雑なモデル（パラメータ数が多いモデル）に対して強いペナルティが課され、**過学習を防止**します。

#### 出力への反映

- **コンソール/レポート**: 推奨モデルの表示に使用された基準（AIC または AICc）を明記
- **Excel**: モデル比較表はSelectionScore（選択基準に応じたスコア）でソート
- **適合度指標**: AIC, AICc, 選択基準のすべてを出力

## 感度分析（Sensitivity Analysis）

パラメータの微小変化に対する予測値の変化率を定量化し、予測のロバスト性（安定性）を評価します。

### 弾力性（Elasticity）の定義

弾力性は、パラメータの相対変化に対する出力の相対変化を表す無次元の指標です。

```text
E_i = (θ_i / Y) × (∂Y / ∂θ_i)

where θ_i = i番目のパラメータ
      Y   = 評価対象の指標（例: 推定総バグ数）
```

### ロバスト性の評価基準

| 弾力性 |E| | ロバスト性 | 解釈 |
|---------|------------|------|
| < 1.0 | 高 | パラメータ変動に対して予測が安定 |
| 1.0 - 5.0 | 中 | 予測にある程度の感度がある |
| 5.0 - 10.0 | 低 | パラメータ推定誤差が予測に大きく影響 |
| ≥ 10.0 | 非常に低 | 予測の信頼性に重大な懸念 |

### レポートへの出力（感度分析）

感度分析の結果は、テキストレポートの「感度分析（パラメータ感度）」セクションに出力されます。弾力性が高い（|E| ≥ 5）パラメータに対しては警告が自動生成されます。

## 堅牢な変化点検出（Profile Likelihood Method）

変化点モデルにおいて、従来のヒューリスティックではなく、プロファイル尤度法による客観的な変化点特定を行います。

### プロファイル尤度法の原理

変化点 τ を固定した状態で他のパラメータを最適化し、各 τ でのAICcを計算します。AICcが最小となる τ を最適変化点として採用します。

```text
τ̂ = argmin_τ { AICc(θ̂(τ), τ) }

where θ̂(τ) = τを固定した時の最適パラメータ
```

### 変化点の信頼性評価

AICcプロファイルの形状（谷の深さ）に基づいて、変化点の信頼性を評価します。

| AICc差（中央値 - 最小値） | 信頼性 | 解釈 |
|--------------------------|--------|------|
| > 10.0 | 高 | 明確な変化点が存在 |
| 4.0 - 10.0 | 中 | 変化点の可能性あり |
| 2.0 - 4.0 | 低 | 弱い変化点 |
| < 2.0 | 非常に低 | 変化点なしの可能性 |

### レポートへの出力（変化点検出）

変化点探索の結果は、テキストレポートの「変化点探索結果（プロファイル尤度法）」セクションに出力されます。最適変化点、AICc、信頼性評価、および上位5候補のプロファイルが表示されます。

### 変化点の尤度比検定（LRT）（v2.0新機能）

変化点の「存在」を統計的に検定する機能です。プロファイル尤度法で最適な変化点位置を見つけた後、その変化点が統計的に有意かどうかを判定します。

#### 検定の原理

尤度比統計量を用いた仮説検定：

```text
H₀: 変化点なし（単一のbパラメータ）
H₁: 変化点あり（b₁, b₂の2つのパラメータ）

LR = -2 × (ln L₀ - ln L₁)
```

#### 境界パラメータ問題への対応

変化点 τ は帰無仮説の下で識別不能（nuisance parameter on the boundary）となるため、通常のχ²分布による近似は不正確です。
本ツールでは **Davies (1987)** のシミュレーション法を採用：

1. 帰無モデル（変化点なし）でデータを生成
2. 生成データに対してLR統計量を計算
3. 多数回（デフォルト: 500回）繰り返してLRの分布を構築
4. 観測LRがシミュレーション分布の何%点にあるかでp値を算出

#### 出力例

```text
=== 変化点尤度比検定 ===
帰無仮説: 変化点なし
対立仮説: Day 25 に変化点あり

LR統計量: 12.34
p値: 0.023 (シミュレーション500回)

判定: 有意水準5%で変化点の存在を支持
```

> **学術的注記**: Davies, R.B. (1987). "Hypothesis testing when a nuisance parameter is present only under the alternative." Biometrika, 74(1), 33-43.

## ホールドアウト検証

予測的妥当性を評価するための機能です。データの末尾N日をテスト用に分割し、残りのデータでパラメータを推定した後、テスト期間の予測精度を評価します。

### 評価指標

| 指標 | 説明 |
|------|------|
| MSE（Mean Squared Error） | 平均二乗誤差。値が小さいほど良い |
| MAE（Mean Absolute Error） | 平均絶対誤差。値が小さいほど良い |
| MAPE（Mean Absolute Percentage Error） | 平均絶対パーセント誤差（%）。値が小さいほど良い |

### ホールドアウトの使用方法

```bash
# 末尾5日をテスト用に使用
BugConvergenceTool TestData.xlsx --holdout-days 5

# MLE推定と組み合わせ
BugConvergenceTool TestData.xlsx --loss mle --holdout-days 5 -v
```

### ホールドアウトの出力

- **コンソール**: 各モデルのホールドアウト検証結果（MSE, MAPE）を表示
- **Excel**: `Holdout_MSE`, `Holdout_MAPE(%)` 列を追加
- **テキストレポート**: 警告セクションにMAPEが高い場合の注意を記載

### 警告メッセージ

以下の条件で自動的に警告が生成されます：

| 条件 | 警告内容 |
|------|---------|
| データ点数 < 7 | パラメータ推定が不安定になる可能性 |
| データ点数 < パラメータ数×3 | 過適合のリスク |
| 総バグ数 < 20 | モデル評価の信頼性が限定的 |
| MAPE > 50% | 将来予測の不確実性が高い |
| MAPE > 100% | モデルの将来予測は信頼できない可能性 |
| 選択モデルのMAPEが他より明らかに高い | 予測性能が低い可能性 |
| R² < 0.9 | データへの当てはまりが不十分 |

## 最適化アルゴリズム

パラメータ推定に使用する最適化アルゴリズムの詳細です。

### アルゴリズム一覧

| コマンド | アルゴリズム名 | 種別 | 特徴 |
|---------|--------------|------|------|
| `de` | 差分進化（DE） | メタヒューリスティック | デフォルト・推奨。非微分可能・マルチモーダル関数に強い |
| `pso` | 粒子群最適化（PSO） | メタヒューリスティック | 群知能に基づく大域的最適化 |
| `gwo` | Grey Wolf Optimizer | メタヒューリスティック | オオカミの群れ行動に基づく最適化 |
| `cmaes` | CMA-ES | 進化戦略 | 共分散行列適応。地形の難しい問題に強い |
| `nm` | Nelder-Mead法 | 直接探索 | 勾配不要・低次元に強い局所最適化 |
| `grid` | グリッドサーチ+勾配降下法 | 従来手法 | グリッドサーチ後に勾配降下で精緻化 |
| `auto` | 自動選択 | - | 全アルゴリズムで比較し最良を選択 |

### マルチスタート最適化（v2.0新機能）

メタヒューリスティック最適化の弱点である「初期点依存性」を軽減するため、Latin Hypercube Sampling（LHS）による多様な初期点からの探索を実装しています。

#### アルゴリズム

1. **初期点の生成**
   - LHSで探索空間を均等に分割し、各次元から1点ずつサンプリング
   - 境界付近（各次元の5%/95%点）からも追加サンプリング
   - デフォルトで5〜10点の初期点を生成

2. **並列最適化**
   - 各初期点から独立に最適化を実行
   - 最良解（最小損失値）を採用

3. **結果の報告**
   - 成功した初期点の数、最良解の損失値を報告
   - 複数の初期点が同程度の解に収束した場合、解の安定性が高いと判断

#### Latin Hypercube Sampling（LHS）の利点

- **空間被覆性**: ランダムサンプリングより均等に探索空間をカバー
- **低不一致性**: 各次元で重複なくサンプリング
- **効率性**: 少ない点数で高い探索効率を実現

```text
例: 3次元、5点のLHS
  点1: (0.1, 0.5, 0.9)
  点2: (0.3, 0.9, 0.1)
  点3: (0.5, 0.1, 0.5)
  点4: (0.7, 0.3, 0.7)
  点5: (0.9, 0.7, 0.3)
→ 各次元で [0.1, 0.3, 0.5, 0.7, 0.9] が1回ずつ出現
```

### パラメータ設定

#### DE（差分進化）

| パラメータ | デフォルト値 | 説明 |
|-----------|-------------|------|
| populationSize | 50 | 個体数 |
| maxIterations | 500 | 最大反復回数 |
| F | 0.8 | スケーリング係数 |
| CR | 0.9 | 交叉率 |
| tolerance | 1e-10 | 収束判定閾値 |

#### PSO（粒子群最適化）

| パラメータ | デフォルト値 | 説明 |
|-----------|-------------|------|
| swarmSize | 30 | 粒子数 |
| maxIterations | 500 | 最大反復回数 |
| w | 0.729 | 慣性重み |
| c1 | 1.49445 | 認知係数（個人最良への引力） |
| c2 | 1.49445 | 社会係数（全体最良への引力） |
| tolerance | 1e-10 | 収束判定閾値 |

#### GWO（Grey Wolf Optimizer）

| パラメータ | デフォルト値 | 説明 |
|-----------|-------------|------|
| packSize | 30 | 群れサイズ |
| maxIterations | 500 | 最大反復回数 |
| tolerance | 1e-10 | 収束判定閾値 |

#### CMA-ES（共分散行列適応進化戦略）

| パラメータ | デフォルト値 | 説明 |
|-----------|-------------|------|
| maxIterations | 500 | 最大反復回数 |
| initialSigmaU | 0.5 | u空間での初期ステップサイズ |
| tolerance | 1e-10 | 収束判定閾値 |
| λ | 4 + floor(3·ln(n)) | 個体数（自動計算） |
| μ | λ / 2 | 選択個体数（自動計算） |

※ CMA-ESはロジスティック変換により無拘束空間で最適化を実行

#### Nelder-Mead法（単体法）

| パラメータ | デフォルト値 | 説明 |
|-----------|-------------|------|
| maxIterations | 1000 | 最大反復回数 |
| tolerance | 1e-10 | 収束判定閾値 |
| α (alpha) | 1.0 | 反射係数 |
| γ (gamma) | 2.0 | 拡大係数 |
| ρ (rho) | 0.5 | 収縮係数 |
| σ (sigma) | 0.5 | 縮小係数 |

#### GridSearch+GD（グリッドサーチ+勾配降下法）

| パラメータ | デフォルト値 | 説明 |
|-----------|-------------|------|
| gridSize | 自動 | グリッドサイズ（次元数に応じて自動設定） |
| maxIterations | 2000 | 勾配降下法の最大反復回数 |
| learningRate | 0.00005 | 学習率 |
| delta | 0.0001 | 数値微分のデルタ |

### パラメータヒューリスティックと個別最適化方針

#### ヒューリスティック定義箇所

- モデルパラメータの初期値と探索範囲は、`Models/*.cs` の `GetInitialParameters` および `GetBounds` で決定されます。初期値のしきい値や倍率は `config.json` で外部設定可能になっており、デフォルト値は `Models/ConfigurationModels.cs` に定義されています。
- オプティマイザのハイパーパラメータ（個体数・反復回数・係数など）も `config.json` でカスタマイズ可能です。デフォルト値は30〜120点程度の一般的なバグ推移データを想定した経験値です。
- 探索範囲の上限・下限（`GetBounds`）はモデルの安全性に直結するため、コード内に固定されています。

#### 初期値の妥当性と修正の指針

- 初期値は、「30〜100日程度である程度収束している典型的な累積欠陥データ」を想定した**経験値ベース**ですが、入力データに応じて自動的に調整されます。
- `a` は終盤の増分（直近2点の差）を見て収束度合いを判定し、設定ファイルの `ScaleFactorA` に基づいてスケール係数を決定します：
  - 収束時（増分 ≤ しきい値）: `1.1〜1.4 × maxY`（デフォルト）
  - 未収束時（増分 > しきい値）: `1.5〜1.9 × maxY`（デフォルト）
- `b` は期間全体の平均増分から、設定ファイルの `AverageSlopeThresholds` に基づいて初期値を決定します（指数型: 0.05〜0.3、S字型: 0.08〜0.35）。
- 変化点 `τ` は、設定ファイルの `ChangePoint.CumulativeRatio`（デフォルト: 0.5）に基づき、累積バグ数がその比率に達する日を初期値とします。
- 専門的な意味での「統計的に最適な初期値」を保証するものではなく、「大域的オプティマイザが迷いにくくなるよう、データのスケールと形状に合わせた無難なスタート地点」を与える設計です。

具体的な修正方針は次の通りです：

- `a`（総バグ数スケール）
  - `config.json` の `ModelInitialization.ScaleFactorA` でスケール係数を調整できます。
  - `IncrementThreshold.ConvergenceThreshold`（デフォルト: 1.0）で収束判定のしきい値を変更できます。
  - 必要に応じて `GetBounds` の上限（`maxY×5` など）をコードで調整することで過大・過小推定を防ぎます。
- `b`, `c`（成長率・形状）
  - `config.json` の `AverageSlopeThresholds` で傾き区分と対応する `b` 初期値を調整できます。
  - ロジスティックや S 字系の `c` は「変曲点の日」に相当するため、`ChangePoint.CumulativeRatio` で調整可能です。
- 変化点 `τ`（Change Point 系）
  - `config.json` の `ChangePoint.CumulativeRatio` で変化点の初期位置を調整できます（デフォルト: 0.5 = 累積50%到達日）。
  - 複数変化点モデルでは `MultipleChangePoints.TwoPointRatios` / `ThreePointRatios` で分割比を設定できます。

#### 個別最適化を行う際の流れ

1. まず `--optimizer de` もしくは `--optimizer auto` で全パラメータを一括推定し、出力されたテキストレポート／Excelで現在値と目的関数値（RMSEや残差）を確認します。
2. 改善したい場合は、`config.json` を編集してオプティマイザのハイパーパラメータ（反復回数、個体数など）やモデル初期値のしきい値を調整します。
3. 特定のパラメータを固定したい場合は、対象モデルの `GetBounds` をコードで編集し、そのパラメータの下限=上限に設定します。
4. 低次元の微調整には `--optimizer nm`（単体法）や `--optimizer grid` を使うのが効果的です。Nelder-Mead で連続的に追い込み、必要なら GridSearch+GD で1変数ずつの感度を確認してください。
5. 調整後は必ず再度 `--optimizer auto` など大域的手法で回し、他のモデル・パラメータとの整合と汎化性能（過剰適合していないか）を確認します。

この手順により、設定ファイルで調整可能なパラメータと、コード内に固定されている範囲設定を明示的にコントロールしつつ、個々のパラメータを安全にチューニングできます。

## 設定ファイル（config.json）

設定ファイルを使用することで、オプティマイザのハイパーパラメータやモデルの初期値推定に使われるしきい値・倍率をカスタマイズできます。

### 設定ファイルの配置場所

以下の順序で設定ファイルが検索されます：

1. `-c, --config` オプションで明示的に指定されたパス
2. カレントディレクトリの `config.json`
3. 実行ファイルと同じディレクトリの `config.json`
4. `Templates/config.json`
5. `Templates/default-config.json`

設定ファイルが見つからない場合は、デフォルト値が使用されます。

### 設定ファイルの構造

```json
{
  "Optimizers": {
    "DE": {
      "PopulationSize": 50,
      "MaxIterations": 500,
      "F": 0.8,
      "CR": 0.9,
      "Tolerance": 1e-10
    },
    "PSO": {
      "SwarmSize": 30,
      "MaxIterations": 500,
      "W": 0.729,
      "C1": 1.49445,
      "C2": 1.49445,
      "Tolerance": 1e-10
    },
    "CMAES": {
      "MaxIterations": 500,
      "InitialSigmaU": 0.5,
      "Tolerance": 1e-10
    },
    "GWO": {
      "PackSize": 30,
      "MaxIterations": 500,
      "Tolerance": 1e-10
    },
    "NelderMead": {
      "MaxIterations": 1000,
      "Tolerance": 1e-10,
      "Alpha": 1.0,
      "Gamma": 2.0,
      "Rho": 0.5,
      "Sigma": 0.5
    },
    "GridSearchGradient": {
      "GridSize": 0,
      "MaxIterations": 2000,
      "LearningRate": 0.00005,
      "Delta": 0.0001
    }
  },
  "ModelInitialization": {
    "ScaleFactorA": {
      "ConvergedMin": 1.1,
      "ConvergedMax": 1.4,
      "NotConvergedMin": 1.5,
      "NotConvergedMax": 1.9
    },
    "IncrementThreshold": {
      "ConvergenceThreshold": 1.0
    },
    "AverageSlopeThresholds": {
      "VeryLow": 0.1,
      "Low": 0.5,
      "Medium": 1.0,
      "BValuesExponential": {
        "VeryLow": 0.05,
        "Low": 0.1,
        "Medium": 0.2,
        "High": 0.3
      },
      "BValuesSCurve": {
        "VeryLow": 0.08,
        "Low": 0.15,
        "Medium": 0.25,
        "High": 0.35
      }
    }
  },
  "ChangePoint": {
    "CumulativeRatio": 0.5,
    "MultipleChangePoints": {
      "TwoPointRatios": [0.33, 0.67],
      "ThreePointRatios": [0.25, 0.5, 0.75]
    }
  },
  "ImperfectDebug": {
    "P0": 0.1,
    "Eta0": 0.8,
    "EtaInfinity": 0.95,
    "Alpha0": 0.1,
    "GompertzB0": 2.0
  }
}
```

### 設定項目の説明

#### オプティマイザ設定（`Optimizers`）

| セクション | パラメータ | 説明 |
|-----------|-----------|------|
| **DE** | `PopulationSize` | 差分進化の個体数（デフォルト: 50） |
| | `MaxIterations` | 最大反復回数（デフォルト: 500） |
| | `F` | スケーリング係数（デフォルト: 0.8） |
| | `CR` | 交叉率（デフォルト: 0.9） |
| **PSO** | `SwarmSize` | 粒子数（デフォルト: 30） |
| | `W` | 慣性重み（デフォルト: 0.729） |
| | `C1`, `C2` | 認知・社会係数（デフォルト: 1.49445） |
| **CMAES** | `InitialSigmaU` | u空間での初期ステップサイズ（デフォルト: 0.5） |
| **GWO** | `PackSize` | 群れサイズ（デフォルト: 30） |
| **NelderMead** | `Alpha`, `Gamma`, `Rho`, `Sigma` | 反射・拡大・収縮・縮小係数 |

#### モデル初期値推定設定（`ModelInitialization`）

| セクション | パラメータ | 説明 |
|-----------|-----------|------|
| **ScaleFactorA** | `ConvergedMin/Max` | 収束時のaスケール係数範囲 |
| | `NotConvergedMin/Max` | 未収束時のaスケール係数範囲 |
| **IncrementThreshold** | `ConvergenceThreshold` | 収束判定の増分しきい値（デフォルト: 1.0） |
| **AverageSlopeThresholds** | `VeryLow`, `Low`, `Medium` | 平均傾き区分のしきい値 |
| | `BValuesExponential` | 指数型モデルのb初期値 |
| | `BValuesSCurve` | S字型モデルのb初期値 |

#### 変化点設定（`ChangePoint`）

| パラメータ | 説明 |
|-----------|------|
| `CumulativeRatio` | 変化点τを決める累積比率（デフォルト: 0.5） |
| `TwoPointRatios` | 2変化点モデルの累積比率 |
| `ThreePointRatios` | 3変化点モデルの累積比率 |

#### 不完全デバッグ設定（`ImperfectDebug`）

| パラメータ | 説明 |
|-----------|------|
| `P0` | 不完全デバッグ係数pの初期値（デフォルト: 0.1） |
| `Eta0` | 初期欠陥除去効率η₀（デフォルト: 0.8） |
| `EtaInfinity` | 漸近欠陥除去効率η∞（デフォルト: 0.95） |
| `Alpha0` | バグ混入率αの初期値（デフォルト: 0.1） |
| `GompertzB0` | ゴンペルツモデルの初期遅延係数（デフォルト: 2.0） |

### カスタマイズ例

#### 計算を軽量化したい場合

```json
{
  "Optimizers": {
    "DE": {
      "PopulationSize": 20,
      "MaxIterations": 200
    },
    "PSO": {
      "SwarmSize": 15,
      "MaxIterations": 200
    }
  }
}
```

#### バグ報告のスケールが大きいプロジェクトの場合

```json
{
  "ModelInitialization": {
    "IncrementThreshold": {
      "ConvergenceThreshold": 5.0
    }
  }
}
```

#### 変化点を早めに設定したい場合

```json
{
  "ChangePoint": {
    "CumulativeRatio": 0.4
  }
}
```

## 信頼区間（ブートストラップ法）

`--ci` オプションを指定すると、最適モデルの予測曲線に対して95%信頼区間を計算します。

### ブートストラップ手法の選択

本ツールでは2種類のブートストラップ手法を実装しています：

| 手法 | 説明 | 適用場面 |
|------|------|----------|
| **残差リサンプリング** | 残差を再サンプリングして擬似データを生成（デフォルト） | 一般的な用途、高速 |
| **パラメトリックPoisson** | NHPP仮定に基づきPoisson分布から日次データを再生成 | 学術的に厳密な分析 |

### 残差リサンプリング（デフォルト）

1. **残差の計算**
   - 元の最適解 θ\* で残差 e\_i = y\_i - m(t\_i; θ\*) を計算
   - 残差をランダムに再サンプリングして擬似データを生成
   - 累積バグ数は非負にクリップ

2. **ブートストラップ最適化**
   - 擬似データに対して軽量オプティマイザ（Nelder-Mead、MaxIterations=80）で再フィッティング
   - 初期値には元の最適解 θ\* を使用
   - SSE が元の10倍以上悪い解は破棄（ロバスト化）

3. **信頼区間の計算**
   - 指定回数（デフォルト: 200回）のブートストラップを並列実行
   - 各時刻 t について予測値のパーセンタイル（2.5%, 97.5%）を計算

### パラメトリックPoisson（NHPP整合）

NHPPの統計的仮定に厳密に従うブートストラップ手法です：

1. **日次期待値の計算**
   - λ\_i = m(t\_i; θ\*) - m(t\_{i-1}; θ\*) を計算（期待される日次バグ数）

2. **Poisson再生成**
   - 各日の擬似観測値 y\*\_i をPoisson(λ\_i)からサンプリング
   - 累積値に変換して擬似累積データを生成

3. **信頼区間の計算**
   - 残差リサンプリングと同様にパラメータを再推定
   - パーセンタイルから信頼区間を算出

> **学術的注記**: パラメトリックPoisson法はNHPPの理論と完全に整合しており、
> 信頼区間の被覆確率（coverage probability）が理論値に近くなります。
> 計算コストは残差リサンプリングとほぼ同等です。

### 信頼区間の使用例

```bash
# 基本的な信頼区間計算
BugConvergenceTool TestData.xlsx --ci

# 反復回数を増やして精度向上（時間がかかる）
BugConvergenceTool TestData.xlsx --ci --bootstrap 500 -v
```

### ブートストラップ設定（config.json）

`config.json` でブートストラップの詳細設定をカスタマイズできます。

```json
{
  "Bootstrap": {
    "Iterations": 200,
    "ConfidenceLevel": 0.95,
    "OptimizerMaxIterations": 80,
    "OptimizerTolerance": 1e-6,
    "SSEThresholdMultiplier": 10.0,
    "RandomSeed": null
  }
}
```

| パラメータ | デフォルト | 説明 |
|-----------|-----------|------|
| `Iterations` | 200 | ブートストラップ反復回数 |
| `ConfidenceLevel` | 0.95 | 信頼水準（0.90 で90%信頼区間、0.99 で99%信頼区間） |
| `OptimizerMaxIterations` | 80 | ブートストラップ用Nelder-Meadの最大反復回数 |
| `OptimizerTolerance` | 1e-6 | ブートストラップ用オプティマイザの収束判定閾値 |
| `SSEThresholdMultiplier` | 10.0 | SSEが元のこの倍数以上悪い解を破棄（0以下で無効） |
| `RandomSeed` | null | ランダムシード（null で自動生成、再現性が必要な場合に指定） |

### 出力

信頼区間を計算すると、信頼度成長曲線のグラフ（`reliability_growth.png`）に予測区間が半透明の帯として描画されます。

### 注意事項

- **計算時間**: ブートストラップは多数の最適化を実行するため、通常の分析より時間がかかります
- **スレッドセーフティ**: `ReliabilityGrowthModelBase.Calculate` は純粋関数（内部状態を持たない）である前提で並列実行されます
- **フォールバック**: ブートストラップ最適化が収束しない場合、またはSSEが閾値を超える場合は元の最適解を使用します
- **軽量オプティマイザ**: ブートストラップでは Nelder-Mead を使用。初期値が元の最適解θ\*なので、局所探索で十分な場合が多い
- **変化点モデル等の多峰性**: 局所極小が多いモデルでは、フォールバック率が高くなる可能性があります

## Fisher情報行列による解析的信頼区間（v2.0新機能）

ブートストラップを使わずに、最尤推定量の漸近理論に基づいて信頼区間を計算する機能です。

### 理論的背景

最尤推定量 θ̂ は、正則条件下で以下の漸近分布に従います：

$$
\hat{\theta} \sim N(\theta, I(\theta)^{-1})
$$

ここで I(θ) はFisher情報行列です。

### NHPP対数尤度のFisher情報行列

本ツールでは、NHPP（非斉次Poisson過程）の対数尤度に基づくFisher情報行列を計算します：

```text
ln L(θ) = Σ [Δyᵢ × ln(λᵢ) - λᵢ - ln(Δyᵢ!)]

where λᵢ = m(tᵢ; θ) - m(tᵢ₋₁; θ)
```

Fisher情報行列は対数尤度のヘッセ行列（2階偏微分行列）の負値：

$$
I(\theta) = -E\left[\frac{\partial^2 \ln L}{\partial \theta_i \partial \theta_j}\right]
$$

### 計算方法

1. **数値微分によるヘッセ行列計算**
   - 中心差分法で2階偏微分を近似
   - δ = max(|θᵢ| × 10⁻⁴, 10⁻⁸) で数値安定性を確保

2. **分散共分散行列の計算**
   - ヘッセ行列の逆行列 H⁻¹ を計算
   - 対角成分が各パラメータの分散推定値

3. **標準誤差と信頼区間**
   - SE(θᵢ) = √(H⁻¹ᵢᵢ)
   - 95%信頼区間: θ̂ᵢ ± 1.96 × SE(θᵢ)

### 出力例

```text
=== Fisher情報行列による標準誤差 ===
パラメータ    推定値      標準誤差    95%信頼区間
    a         156.3       8.2       [140.2, 172.4]
    b         0.082       0.012     [0.058, 0.106]
```

### ブートストラップとの比較

| 特徴 | Fisher情報行列 | ブートストラップ |
|------|---------------|------------------|
| 計算速度 | 高速（1回の微分計算） | 低速（多数の再推定） |
| 理論的仮定 | 漸近正規性、正則条件 | 特になし（ノンパラメトリック） |
| 小標本性能 | やや不正確 | 一般に良好 |
| 多峰性問題 | 局所最適解周辺のみ評価 | 大域的な不確実性を反映 |

> **推奨**: 大標本（n > 50）かつ単峰性の問題ではFisher情報行列法が効率的。
> 小標本や複雑なモデルではブートストラップを推奨。

## 統計診断機能の詳細

`-d`/`--diagnostics` オプションで、フィッティング結果の統計的妥当性を評価できます。

### 診断項目

#### 1. 残差分析

| 残差タイプ | 計算式 | 用途 |
|-----------|--------|------|
| 生残差（Raw） | e\_i = Δy\_i - Δm(t\_i) | 基本的な乖離の確認（増分ベース） |
| Pearson残差 | (Δy\_i - λ\_i) / √λ\_i | 分散安定化、Poisson仮定下で近似正規 |
| Deviance残差 | sign(Δy - λ) × √(2 × deviance\_i) | NHPPモデルに適合、GLMの逸脱度分解 |
| Anscombe残差 | 1.5 × (y^(2/3) - λ^(2/3)) / λ^(1/6) | より正規性に近い分布（分散安定化変換） |
| ランダム化分位残差 | Φ⁻¹(u), u ∈ [F(y-1), F(y)] | 離散分布でも正規性検定が可能 |

> **注意**: 増分ベースの残差（Raw, Pearson, Deviance, Anscombe）はNHPPの独立性仮定と整合します。
> 累積ベースの残差は自己相関を持つため、独立性検定の解釈に注意が必要です。

#### Poisson整合性診断（v2.0新機能）

| 診断項目 | 説明 | 判定基準 |
|---------|------|----------|
| **過分散検定** | φ = Pearsonχ²/df でPoisson仮定を検証 | φ > 1.5 で過分散 |
| **ゼロ過剰検出** | 観測ゼロ数と期待ゼロ数を比較 | 1.5倍以上でZIPモデル推奨 |
| **小λ警告** | λ < 5 のデータ点を検出 | 30%以上で正規近似に注意 |

**過分散パラメータ φ の解釈**:

| φ値 | 状態 | 推奨アクション |
|-----|------|---------------|
| < 0.8 | 過小分散 | データに制約がある可能性 |
| 0.8〜1.2 | 等分散 | Poisson仮定は妥当 |
| 1.2〜1.5 | 軽度過分散 | 概ね妥当、やや注意 |
| 1.5〜3.0 | 中程度過分散 | quasi-Poissonモデル推奨 |
| > 3.0 | 重度過分散 | 負の二項分布モデル推奨 |

#### 2. 自己相関検定

| 検定名 | 帰無仮説 | 統計量の目安 |
|--------|---------|-------------|
| Durbin-Watson | 1次自己相関なし | 2に近いほど良好（1.5〜2.5が許容範囲） |
| Ljung-Box Q | ラグkまで自己相関なし | p値 > 0.05 で帰無仮説採択 |

#### 3. 正規性検定

| 検定名 | 対象 | 解釈 |
|--------|------|------|
| Jarque-Bera | 歪度・尖度 | p値 > 0.05 で正規性を支持 |
| Anderson-Darling | 分布の裾 | p値 > 0.05 で正規性を支持 |

#### 4. 適合度検定

| 検定名 | 特徴 | 適用条件 |
|--------|------|---------|
| χ²検定 | 伝統的、区間データ | 期待度数 ≥ 5（Cochranの規則） |
| Kolmogorov-Smirnov | 分布全体 | 連続分布 |
| Cramér-von Mises | 裾に敏感 | 連続分布 |

### 診断グレード

診断結果は0〜100のスコアと5段階のグレードで評価されます：

| グレード | スコア | 意味 |
|---------|-------|------|
| Excellent | 90〜100 | モデル仮定が十分に満たされている |
| Good | 75〜89 | 軽微な問題があるが実用上問題なし |
| Acceptable | 60〜74 | 注意が必要だが使用可能 |
| Caution | 40〜59 | モデル選択の再検討を推奨 |
| Poor | 0〜39 | モデルが不適切、再検討必須 |

### 診断の実行例

```bash
# 診断を実行
BugConvergenceTool TestData.xlsx -d

# 詳細出力
BugConvergenceTool TestData.xlsx -d -v
```

### 出力例

```text
=== 診断レポート: 遅延S字型 ===
診断スコア: 78/100 (Good)

[残差分析]
  残差タイプ: Pearson
  平均: 0.023 (理想: 0)
  標準偏差: 1.12
  ラン検定 p値: 0.342 (独立性: OK)

[自己相関]
  Durbin-Watson: 1.87 (許容範囲内)
  Ljung-Box Q(10) p値: 0.156 (自己相関なし)

[正規性]
  Jarque-Bera p値: 0.234 (正規性を支持)
  Anderson-Darling p値: 0.198 (正規性を支持)

[適合度]
  χ² p値: 0.089 (適合)
  KS p値: 0.312 (適合)
```

## 予測区間の詳細

`--pi`/`--prediction-interval` オプションで、将来の観測値に対する予測区間を計算できます。

### 信頼区間との違い

| 区間タイプ | 対象 | 不確実性の源泉 |
|-----------|------|---------------|
| 信頼区間 | 期待値 m(t) | パラメータ推定誤差のみ |
| 予測区間 | 将来の観測値 Y(t) | パラメータ推定誤差 + 観測のばらつき |

予測区間は常に信頼区間より広くなります。

### アルゴリズム

1. **パラメトリックブートストラップ**
   - 推定パラメータ θ\* からPoisson過程でデータを再生成
   - 再生成データに対してモデルを再フィッティング
   - 多数（デフォルト: 200回）繰り返し

2. **区間の計算**
   - 各時点でブートストラップ予測値の分位点を計算
   - 95%予測区間: 2.5%〜97.5%分位点

### 予測区間の計算例

```bash
# 予測区間を計算
BugConvergenceTool TestData.xlsx --pi

# 反復回数を増やして精度向上
BugConvergenceTool TestData.xlsx --pi --bootstrap 500 -v
```

## モデル平均化の詳細

`--ma`/`--model-averaging` オプションで、複数モデルのAIC重み付け平均予測を実行できます。

### 理論的背景

単一の「最良」モデルを選択する代わりに、複数のモデルからの予測を重み付け平均することで、モデル選択の不確実性を予測に反映させます（Burnham & Anderson, 2002）。

### AIC重みの計算

$$
w_i = \frac{\exp(-\Delta_i / 2)}{\sum_j \exp(-\Delta_j / 2)}
$$

ここで $\Delta_i = AIC_i - AIC_{min}$ です。

### 出力内容

```text
=== モデル平均化結果 ===

[モデル重み]
  遅延S字型:     0.412
  ゴンペルツ:    0.298
  指数型:        0.187
  修正ゴンペルツ: 0.103

[収束予測（重み付け平均）]
  推定総バグ数:  156.3 ± 12.8
  90%収束日:     Day 45 ± 3.2日
  95%収束日:     Day 52 ± 4.1日
  99%収束日:     Day 68 ± 6.5日

[不確実性の内訳]
  パラメータ不確実性: 65%
  モデル不確実性:     35%
```

### モデル平均化の注意点

- 重みが0.9以上のモデルが存在する場合、実質的にそのモデルが支配的
- 複数モデルが同程度の重みを持つ場合、モデル不確実性が大きい
- 全拡張モデル（`--all-extended`）と組み合わせると、より多様なモデルで平均化

## ライセンス

MIT License

### 使用ライブラリ

| ライブラリ | ライセンス | 用途 |
|-----------|-----------|------|
| [ClosedXML](https://github.com/ClosedXML/ClosedXML) | MIT | Excel読み書き |
| [MathNet.Numerics](https://numerics.mathdotnet.com/) | MIT | 数値計算 |
| [ScottPlot](https://scottplot.net/) | MIT | グラフ画像生成 |

## 参考文献

本ツールの拡張機能は以下の学術研究領域を参考に実装：

- Software Reliability Growth Models (SRGM)
- Change Point Models in Software Reliability
- Test Effort Functions in SRGM
- Fault Removal Efficiency Models
- Metaheuristic Optimization for Parameter Estimation
- Residual Diagnostics for Count Data (Durbin-Watson, Ljung-Box)
- Normality Tests (Jarque-Bera, Anderson-Darling)
- Goodness-of-Fit Tests for NHPP (χ², KS, Cramér-von Mises)
- Model Averaging and Multi-Model Inference (Burnham & Anderson, 2002)
- Davies, R.B. (1987). "Hypothesis testing when a nuisance parameter is present only under the alternative." Biometrika, 74(1), 33-43. (変化点尤度比検定)
- Dunn, P.K. & Smyth, G.K. (1996). "Randomized quantile residuals." Journal of Computational and Graphical Statistics, 5(3), 236-244. (ランダム化分位残差)
- McKay, M.D., Beckman, R.J. & Conover, W.J. (1979). "A comparison of three methods for selecting values of input variables in the analysis of output from a computer code." Technometrics, 21(2), 239-245. (Latin Hypercube Sampling)
